# -*- coding: utf-8 -*-
"""test_gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13B5Rj8IWbzx5JCo-MBjECPogRyzdAAi8
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable

matplotlib_is_available = True
try:
  from matplotlib import pyplot as plt
except ImportError:
  print("Will skip plotting; matplotlib is not available.")
  matplotlib_is_available = False

# Data params
data_mean = 4
data_stddev = 1.25

(name, preprocess, d_input_func) = ("Only 4 moments", lambda data: get_moments(data), lambda x: 4)

print("Using data [%s]" % (name))

def get_distribution_sampler(mu, sigma):
    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian

def get_generator_input_sampler():
    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian

class Generator(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, f):
        super(Generator, self).__init__()
        self.map1 = nn.Linear(input_size, hidden_size)
        self.map2 = nn.Linear(hidden_size, hidden_size)
        self.map3 = nn.Linear(hidden_size, output_size)
        self.f = f

    def forward(self, x):
        x = self.map1(x)
        x = self.f(x)
        x = self.map2(x)
        x = self.f(x)
        x = self.map3(x)
        return x

class Discriminator(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, f):
        super(Discriminator, self).__init__()
        self.map1 = nn.Linear(input_size, hidden_size)
        self.map2 = nn.Linear(hidden_size, hidden_size)
        self.map3 = nn.Linear(hidden_size, output_size)
        self.f = f

    def forward(self, x):
        x = self.f(self.map1(x))
        x = self.f(self.map2(x))
        return self.f(self.map3(x))

def extract(v):
    return v.data.storage().tolist()

def stats(d):
    return [np.mean(d), np.std(d)]

def get_moments(d):
    # Return the first 4 moments of the data provided
    mean = torch.mean(d)
    diffs = d - mean
    var = torch.mean(torch.pow(diffs, 2.0))
    std = torch.pow(var, 0.5)
    zscores = diffs / std
    skews = torch.mean(torch.pow(zscores, 3.0))
    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian
    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))
    return final

def decorate_with_diffs(data, exponent, remove_raw_data=False):
    mean = torch.mean(data.data, 1, keepdim=True)
    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])
    diffs = torch.pow(data - Variable(mean_broadcast), exponent)
    if remove_raw_data:
        return torch.cat([diffs], 1)
    else:
        return torch.cat([data, diffs], 1)

d_sampler = get_distribution_sampler(data_mean, data_stddev)

d_real_data = Variable(d_sampler(2))
d_real_data

g_input_size = 1  # Random noise dimension coming into generator, per output vector
g_hidden_size = 5 # Generator complexity
g_output_size = 1 # Size of generated output vector
d_input_size = 500# Minibatch size - cardinality of distributions
d_hidden_size = 10# Discriminator complexity
d_output_size = 1 # Single dimension for 'real' vs. 'fake' classification
minibatch_size = d_input_size

discriminator_activation_function = torch.sigmoid
    generator_activation_function = torch.tanh

G = Generator(input_size=g_input_size,
              hidden_size=g_hidden_size,
              output_size=g_output_size,
              f=generator_activation_function)
D = Discriminator(input_size=d_input_func(d_input_size),
                  hidden_size=d_hidden_size,
                  output_size=d_output_size,
                  f=discriminator_activation_function)

D.zero_grad()

d_real_data = Variable(d_sampler(d_input_size))
d_real_decision = D(preprocess(d_real_data))

preprocess(d_real_data)

def generate_circle_points(n, center, device):
    """ return random samples from the circumference of a circle
        with added noise """
    # draw n thetas (angle)
    thetas = torch.rand(n) * 2 * np.pi
    x = np.cos(thetas) + center[0]
    y = np.sin(thetas) + center[1]

    # add random noise
    x += 0.25 * torch.rand(n)
    y += 0.25 * torch.rand(n)
    # reshape
    x = x.view(n, 1)
    y = y.view(n, 1)

    # put x in col[0] and y in col[1]
    return torch.cat((x, y), 1).to(device)

def generator_circle_data(device, center=(2, 2)):
    """ return random samples from the circumference of a circle
    with added noise """
    return lambda n: generate_circle_points(n, center, device)

device = 'cuda'

real_data_generator = generator_circle_data(device, (2, 2))

d_real_data = real_data_generator(100)

D = Discriminator(input_size=512,
  hidden_size=10,
  output_size=1,
  f=torch.sigmoid)

D(d_real_data)

