# -*- coding: utf-8 -*-
"""Gans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YveMvFq8LEgt-UUhlk9jb9xYXt3EbI3a

# DCGAN using Fashion-MNIST
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras import backend as K
from keras.models import Sequential
from keras.layers import Reshape, Activation, Dense, Conv2D, Dropout
from keras.layers import Flatten, BatchNormalization, UpSampling2D, Conv2DTranspose
from keras.optimizers import RMSprop

"""### Dataset - Fashion MNIST"""

fashion_mnist = keras.datasets.fashion_mnist
(train_image, train_label), (test_image, test_label) = fashion_mnist.load_data()

train_image.shape

train_image= train_image.reshape(-1, 28,28, 1).astype(np.float32)

train_image.shape

"""## Discriminator"""

def Disc():
    print('Hey, I am Discriminator. You can call me Disco.')
    depth = 64
    dropout = .4
    channel = 1
    #INPUT 28x28
    input_shape = (train_image[0].shape[0], train_image[0].shape[1], channel)
    Discriminator = Sequential()
    Discriminator.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,padding='same'))
    Discriminator.add(Activation('relu'))
    Discriminator.add(Dropout(dropout))
    Discriminator.add(Conv2D(depth*2, 5, strides=2, input_shape=input_shape,padding='same'))
    Discriminator.add(Activation('relu'))
    Discriminator.add(Dropout(dropout))
    Discriminator.add(Conv2D(depth*4, 5, strides=2, input_shape=input_shape,padding='same'))
    Discriminator.add(Activation('relu'))
    Discriminator.add(Dropout(dropout))
    Discriminator.add(Conv2D(depth*8, 5, strides=2, input_shape=input_shape,padding='same'))
    Discriminator.add(Activation('relu'))
    Discriminator.add(Dropout(dropout))
    Discriminator.add(Flatten())
    Discriminator.add(Dense(1))
    Discriminator.add(Activation('sigmoid'))
    #Discriminator.summary()
    return Discriminator

"""## Generator"""

def Gen():
    print('Hey, I am Generator. You can call me Genko.')
    Generator =Sequential()
    dropout = 0.4
    depth = 64+64+64+64
    dim = 7
    Generator.add(Dense(dim*dim*depth, input_dim =100))
    Generator.add(BatchNormalization(momentum=0.9))
    Generator.add(Activation('relu'))
    Generator.add(Reshape((dim, dim, depth)))
    Generator.add(Dropout(dropout))
    #INPUT - dimxdimxdepth
    #Output - 2* dim x 2*dim x depth/2
    Generator.add(UpSampling2D())
    Generator.add(Conv2DTranspose(int(depth/2),5,padding ='same'))
    Generator.add(BatchNormalization(momentum=0.9))
    Generator.add(Activation('relu'))
    Generator.add(UpSampling2D())
    Generator.add(Conv2DTranspose(int(depth/4),5,padding ='same'))
    Generator.add(BatchNormalization(momentum=0.9))
    Generator.add(Activation('relu'))
    Generator.add(Conv2DTranspose(int(depth/8),5,padding ='same'))
    Generator.add(BatchNormalization(momentum=0.9))
    Generator.add(Activation('relu'))
    Generator.add(Conv2DTranspose(1,5, padding='same'))
    Generator.add(Activation('sigmoid'))
    #Generator.summary()
    return Generator

"""### Discriminator Model"""

def Disc_M(noise, y):
    optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)
    Disc_model = Sequential([
        Disc()
    ])
    Disc_model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])
    return Disc_model.train_on_batch(noise, y)

"""## GAN full"""

def DCGAN(x,y):
    optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)
    GAN_model = Sequential([
        Gen(),
        Disc()
    ])
    GAN_model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])
    return GAN_model.train_on_batch(x, y)

"""## How to train your DCGAN"""

def train_dcgan(steps = 2000, batch_size = 256, save_interval=0):
    if save_interval>0:
            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])
    for i in range(steps):
        images_real = train_image[np.random.randint(0, train_image.shape[0], size=batch_size), :, :,:]
        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])
        images_fake = Gen().predict(noise)
        x = np.concatenate((images_real, images_fake))
        y = np.ones([2*batch_size, 1])
        y[batch_size:, :] = 0
        #d_loss = Disc_M().train_on_batch(x, y)
        d_loss = Disc_M(x,y)
        y = np.ones([batch_size, 1])
        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])
        #a_loss = DCGAN.train_on_batch(noise, y)
        a_loss = DCGAN(noise,y)
        log_mesg = "%d: [D loss: %f, acc: %f]" % (i, d_loss[0], d_loss[1])
        log_mesg = "%s  [A loss: %f, acc: %f]" % (log_mesg, a_loss[0], a_loss[1])
        print(log_mesg)
        if save_interval>0:
            if (i+1)%save_interval==0:
                self.plot_images(save2file=True, samples=noise_input.shape[0],\
                noise=noise_input, step=(i+1))

def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):
    filename = 'mnist.png'
    if fake:
        if noise is None:
            noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])
        else:
            filename = "mnist_%d.png" % step
        images = Gen().predict(noise)
    else:
        i = np.random.randint(0, self.x_train.shape[0], samples)
        images = train_image[i, :, :, :]
    plt.figure(figsize=(10,10))
    for i in range(images.shape[0]):
        plt.subplot(4, 4, i+1)
        image = images[i, :, :, :]
        image = np.reshape(image, [self.img_rows, self.img_cols])
        plt.imshow(image, cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    if save2file:
        plt.savefig(filename)
        plt.close('all')
    else:
        plt.show()

import time
start_time = time.time()

train_dcgan(steps=100, batch_size=256, save_interval=500)


end_time = time.time()
elapsed = start_time-end_time
print('Seconds elapsed: ' +str(elapsed))

