{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3-Q2-VAE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q85BwZSsj_B"
      },
      "source": [
        "**Work in progress !!**\n",
        "\n",
        "***Task Completed :***\n",
        "\n",
        "*   Architecture\n",
        "*   Train VAE\n",
        "*   Implement ELBO\n",
        "*   Achieve an ELBO of ≥−96\n",
        "*   Returns:–(logp(x1),...,logp(xM)) estimates of size (M,)\n",
        "\n",
        "***To Do:***\n",
        "* Nothing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNrPKkzu9R4J"
      },
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOwcsoJb9b_f"
      },
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location, filename = filename, md5=None)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv_8Y33A9nCU",
        "outputId": "6623d49a-051d-4b9c-da1e-094fa6020737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "epochs = 20\n",
        "bs = 128\n",
        "\n",
        "train, valid, test = get_data_loader(\"binarized_mnist\", bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/78400000 [00:00<09:18, 140325.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "78405632it [00:30, 5701191.78it/s]                              \n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "  0%|          | 49152/15680000 [00:00<00:33, 461126.14it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  3%|▎         | 425984/15680000 [00:00<00:24, 625716.92it/s]\u001b[A\n",
            "  6%|▌         | 933888/15680000 [00:00<00:17, 846422.04it/s]\u001b[A\n",
            " 10%|▉         | 1548288/15680000 [00:00<00:12, 1139998.39it/s]\u001b[A\n",
            " 15%|█▍        | 2293760/15680000 [00:00<00:08, 1524405.25it/s]\u001b[A\n",
            " 20%|██        | 3186688/15680000 [00:00<00:06, 2028593.99it/s]\u001b[A\n",
            " 27%|██▋       | 4276224/15680000 [00:00<00:04, 2682811.16it/s]\u001b[A\n",
            " 34%|███▎      | 5283840/15680000 [00:00<00:03, 3436357.37it/s]\u001b[A\n",
            " 39%|███▉      | 6184960/15680000 [00:00<00:02, 4209063.84it/s]\u001b[A\n",
            " 45%|████▍     | 7020544/15680000 [00:01<00:01, 4501498.29it/s]\u001b[A\n",
            " 50%|████▉     | 7766016/15680000 [00:01<00:01, 4471363.85it/s]\u001b[A\n",
            " 54%|█████▎    | 8421376/15680000 [00:01<00:01, 4521983.78it/s]\u001b[A\n",
            " 58%|█████▊    | 9019392/15680000 [00:01<00:01, 4656849.35it/s]\u001b[A\n",
            " 61%|██████    | 9592832/15680000 [00:01<00:01, 4715592.93it/s]\u001b[A\n",
            " 65%|██████▍   | 10141696/15680000 [00:01<00:01, 4751349.70it/s]\u001b[A\n",
            " 68%|██████▊   | 10674176/15680000 [00:01<00:01, 4873996.90it/s]\u001b[A\n",
            " 72%|███████▏  | 11214848/15680000 [00:01<00:00, 4985657.28it/s]\u001b[A\n",
            " 75%|███████▌  | 11763712/15680000 [00:02<00:00, 5125083.35it/s]\u001b[A\n",
            " 79%|███████▊  | 12328960/15680000 [00:02<00:00, 5228764.87it/s]\u001b[A\n",
            " 82%|████████▏ | 12902400/15680000 [00:02<00:00, 5367078.80it/s]\u001b[A\n",
            " 86%|████████▌ | 13492224/15680000 [00:02<00:00, 5510255.21it/s]\u001b[A\n",
            " 90%|████████▉ | 14082048/15680000 [00:02<00:00, 5599671.80it/s]\u001b[A\n",
            " 94%|█████████▎| 14696448/15680000 [00:02<00:00, 5752375.46it/s]\u001b[A\n",
            " 98%|█████████▊| 15302656/15680000 [00:02<00:00, 5841153.05it/s]\u001b[A\n",
            "15687680it [00:02, 5783540.86it/s]                              \u001b[A\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "  0%|          | 49152/15680000 [00:00<00:34, 453997.46it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  3%|▎         | 507904/15680000 [00:00<00:24, 622086.00it/s]\u001b[A\n",
            "  7%|▋         | 1056768/15680000 [00:00<00:17, 847515.91it/s]\u001b[A\n",
            " 11%|█         | 1712128/15680000 [00:00<00:12, 1144879.74it/s]\u001b[A\n",
            " 16%|█▌        | 2531328/15680000 [00:00<00:08, 1542673.07it/s]\u001b[A\n",
            " 22%|██▏       | 3522560/15680000 [00:00<00:05, 2060730.53it/s]\u001b[A\n",
            " 30%|███       | 4743168/15680000 [00:00<00:03, 2744802.78it/s]\u001b[A\n",
            " 38%|███▊      | 6004736/15680000 [00:00<00:02, 3586316.72it/s]\u001b[A\n",
            " 44%|████▍     | 6955008/15680000 [00:00<00:02, 4323971.72it/s]\u001b[A\n",
            " 50%|█████     | 7872512/15680000 [00:01<00:01, 5106067.51it/s]\u001b[A\n",
            " 56%|█████▌    | 8781824/15680000 [00:01<00:01, 5330347.20it/s]\u001b[A\n",
            " 61%|██████    | 9601024/15680000 [00:01<00:01, 5326975.54it/s]\u001b[A\n",
            " 66%|██████▌   | 10330112/15680000 [00:01<00:01, 5305066.70it/s]\u001b[A\n",
            " 70%|███████   | 11001856/15680000 [00:01<00:00, 5509425.74it/s]\u001b[A\n",
            " 74%|███████▍  | 11657216/15680000 [00:01<00:00, 5494429.82it/s]\u001b[A\n",
            " 78%|███████▊  | 12279808/15680000 [00:01<00:00, 5543479.00it/s]\u001b[A\n",
            " 82%|████████▏ | 12886016/15680000 [00:01<00:00, 5682841.73it/s]\u001b[A\n",
            " 86%|████████▌ | 13500416/15680000 [00:02<00:00, 5806625.46it/s]\u001b[A\n",
            " 90%|█████████ | 14139392/15680000 [00:02<00:00, 5965261.57it/s]\u001b[A\n",
            " 94%|█████████▍| 14778368/15680000 [00:02<00:00, 6076766.06it/s]\u001b[A\n",
            " 98%|█████████▊| 15441920/15680000 [00:02<00:00, 6229514.18it/s]\u001b[A\n",
            "15687680it [00:02, 6641940.90it/s]                              \u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSwlEYJz9qik",
        "outputId": "44c88139-7766-4ba3-d627-609603056444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Z9N4cK9qf8"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input, size=256):\n",
        "        return input.view(input.size(0), size, 1, 1)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  \n",
        "    def __init__(self, image_channels=1, h_dim=256, z_dim=100):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Q(z|X) -- encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 256, kernel_size=5),\n",
        "            nn.ELU(),\n",
        "            Flatten()\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        # P(X|z) -- decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            \n",
        "            UnFlatten(),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(256, 64, kernel_size= 5, padding= 4),\n",
        "            nn.ELU(),\n",
        "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=2),\n",
        "            nn.ELU(),\n",
        "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding = 2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(16, image_channels, kernel_size = 3, padding = 2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "      \n",
        "        \"\"\"std = logvar.mul(0.5).exp_()\n",
        "        esp = torch.randn(*mu.size())\n",
        "        z = mu + std * esp\"\"\"\n",
        "        eps = torch.randn(mu.size()).cuda()\n",
        "        z = eps.mul(logvar.mul(0.5).exp_()).add_(mu)\n",
        "          \n",
        "        logq_xz = torch.distributions.MultivariateNormal(mu,  torch.eye(100).cuda())\n",
        "        q_xz = logq_xz.log_prob(z)\n",
        "        \n",
        "        log_p_z = torch.distributions.MultivariateNormal(torch.zeros(100).cuda(), torch.eye(100).cuda())\n",
        "        p_z = log_p_z.log_prob(z)\n",
        "                \n",
        "        return z, q_xz, p_z\n",
        "\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu, logvar = self.fc1(h), self.fc2(h)\n",
        "        z, q_xz, p_z = self.reparameterize(mu, logvar)\n",
        "        return z, q_xz, p_z, mu, logvar\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        h = self.encoder(x)\n",
        "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
        "        z_decoder = self.fc3(z)\n",
        "        decoder = self.decoder(z_decoder)\n",
        "        \n",
        "        return decoder, mu, logvar\n",
        "      \n",
        "    def imp_sample(self, x, h):\n",
        "        \n",
        "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
        "        \n",
        "        z_decoder = self.fc3(z)\n",
        "        decoder = self.decoder(z_decoder)\n",
        "        \n",
        "        log_p_xz = torch.distributions.Bernoulli(decoder.view(decoder.size(0),784))\n",
        "        p_xz = log_p_xz.log_prob(x.view(x.size(0),784))\n",
        "        \n",
        "        return p_xz, q_xz, p_z\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSSFbJNzIL2r"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "model = VAE().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss(reduction = \"sum\").cuda()\n",
        "\n",
        "def loss_fn(recon_x, x, mu, logvar):\n",
        "    ## E[log P(X|z)]\n",
        "    \n",
        "    BCE = criterion(recon_x, x)\n",
        "    KLD = - 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp() )\n",
        "    return BCE + KLD, BCE, KLD\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIC-9Bj-9qVk",
        "outputId": "1873dd9f-c1e0-464b-ae9a-f35e1c2715be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(train):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_kld/total_images)\n",
        "    print(\"Training Data : \", to_print)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Data :  Epoch[1/20] ELBO: -210.933 ,BCE: 196.092 ,KLD: 14.841\n",
            "Training Data :  Epoch[2/20] ELBO: -140.425 ,BCE: 118.298 ,KLD: 22.127\n",
            "Training Data :  Epoch[3/20] ELBO: -121.912 ,BCE: 98.859 ,KLD: 23.053\n",
            "Training Data :  Epoch[4/20] ELBO: -113.155 ,BCE: 89.314 ,KLD: 23.841\n",
            "Training Data :  Epoch[5/20] ELBO: -108.607 ,BCE: 84.276 ,KLD: 24.332\n",
            "Training Data :  Epoch[6/20] ELBO: -105.808 ,BCE: 81.057 ,KLD: 24.751\n",
            "Training Data :  Epoch[7/20] ELBO: -104.029 ,BCE: 78.970 ,KLD: 25.059\n",
            "Training Data :  Epoch[8/20] ELBO: -102.484 ,BCE: 77.206 ,KLD: 25.278\n",
            "Training Data :  Epoch[9/20] ELBO: -101.230 ,BCE: 75.737 ,KLD: 25.493\n",
            "Training Data :  Epoch[10/20] ELBO: -100.229 ,BCE: 74.586 ,KLD: 25.642\n",
            "Training Data :  Epoch[11/20] ELBO: -99.372 ,BCE: 73.607 ,KLD: 25.764\n",
            "Training Data :  Epoch[12/20] ELBO: -98.727 ,BCE: 72.862 ,KLD: 25.865\n",
            "Training Data :  Epoch[13/20] ELBO: -98.081 ,BCE: 72.154 ,KLD: 25.926\n",
            "Training Data :  Epoch[14/20] ELBO: -97.564 ,BCE: 71.536 ,KLD: 26.027\n",
            "Training Data :  Epoch[15/20] ELBO: -97.139 ,BCE: 71.107 ,KLD: 26.032\n",
            "Training Data :  Epoch[16/20] ELBO: -96.746 ,BCE: 70.667 ,KLD: 26.078\n",
            "Training Data :  Epoch[17/20] ELBO: -96.332 ,BCE: 70.258 ,KLD: 26.075\n",
            "Training Data :  Epoch[18/20] ELBO: -96.005 ,BCE: 69.891 ,KLD: 26.114\n",
            "Training Data :  Epoch[19/20] ELBO: -95.635 ,BCE: 69.525 ,KLD: 26.110\n",
            "Training Data :  Epoch[20/20] ELBO: -95.349 ,BCE: 69.236 ,KLD: 26.113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PQZAB6X9qK8"
      },
      "source": [
        "# Q(z|X) -- encoder\n",
        "# P(X|z) -- decoder\n",
        "#p(z) -- latent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5g6mTp92ffR",
        "outputId": "8aacc0b8-dc7d-49d2-e07d-cde86866c977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#ELBO Validation Data:\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(valid):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "\n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_kld/total_images)\n",
        "    print(\"Validation Data : \", to_print)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Data :  Epoch[1/1] ELBO: -95.262 ,BCE: 69.002 ,KLD: 26.260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8eu7RC32jDo",
        "outputId": "16807360-81c9-4400-ac07-ea01d3839ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#ELBO Test Data:\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(test):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "\n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_kld/total_images)\n",
        "    print(\"Test Data : \", to_print)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Data :  Epoch[1/1] ELBO: -94.578 ,BCE: 68.437 ,KLD: 26.141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Os3QJwSSYa"
      },
      "source": [
        "#Importance Sampling Function:\n",
        "\n",
        "def importance_sampling(model, data):\n",
        "    #Input as our trained model and data\n",
        "  \n",
        "    ip_loss = []\n",
        "    count = 0\n",
        "    #Setting the model parameters to no_grad\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    for idx, (images) in enumerate(valid):\n",
        "        images = images.to(device)\n",
        "        count += 1\n",
        "        #Calling model to get the output from encoder\n",
        "        h = model.encoder(images.view(images.size(0),1,28,28))\n",
        "        h = h.view(images.size(0),256)\n",
        "\n",
        "        ip_sample = []\n",
        "\n",
        "        for k in range(200):\n",
        "            #Calling model to get output of our densities :\n",
        "            p_xz, q_xz, p_z = model.imp_sample(images, h)\n",
        "            #Summing over 784 dimention and the dimention we will have (1XBatch_Size)\n",
        "            p_xz = torch.sum(p_xz,dim=1)\n",
        "            #Importance Sampling calculation with LogSumExp trick:\n",
        "            out = p_xz - q_xz + p_z\n",
        "            log_weight = out - torch.max(out, 0)[0]\n",
        "            weight = torch.exp(log_weight)\n",
        "            weight = weight / torch.sum(weight, 0)\n",
        "            loss = torch.mean(torch.sum(weight * (p_z + p_xz - q_xz), 0))\n",
        "            ip_sample.append(loss)\n",
        "\n",
        "        ip_loss.append(torch.sum(torch.stack(ip_sample))/bs)\n",
        "\n",
        "        print(\"Importance Sampling over mini batch -\", count,' : ' , torch.stack(ip_loss))\n",
        "\n",
        "    log_likelihood_estimate = torch.mean(torch.stack(ip_loss))\n",
        "    print('log-likelihood  estimate :', log_likelihood_estimate)\n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyoSgq28TiRD",
        "outputId": "5deb9207-a50b-4a2a-faa7-5ff5d4af9a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Importance Sampling on Validation Data:\n",
        "importance_sampling(model, valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBw7wyMTu-P",
        "outputId": "bb0be6be-92dc-4080-ec05-af3d9b71d5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "#Importance Sampling on Test Data:\n",
        "importance_sampling(model, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Importance Sampling over mini batch - 79  :  tensor([-52.7593, -40.0179, -41.9021, -45.2148, -42.6764, -39.3741, -47.6158,\n",
            "        -52.9541, -50.1207, -48.1770, -48.9691, -44.5730, -45.4469, -44.9750,\n",
            "        -43.2122, -41.7132, -47.1530, -49.3909, -43.6133, -47.1973, -44.5091,\n",
            "        -48.9313, -48.9874, -49.7999, -46.9914, -43.9255, -45.9558, -46.7268,\n",
            "        -46.8406, -44.5671, -42.7406, -49.5476, -46.8566, -41.7708, -42.2490,\n",
            "        -39.5359, -46.7262, -44.4517, -44.9979, -49.2932, -49.8515, -42.4823,\n",
            "        -45.5436, -43.9188, -41.7588, -42.5834, -41.6650, -44.7643, -45.8705,\n",
            "        -50.3985, -47.8573, -46.7541, -36.1047, -44.6856, -49.3110, -47.2863,\n",
            "        -45.1809, -43.8301, -44.9362, -48.1151, -43.8392, -49.3516, -41.7667,\n",
            "        -43.7730, -46.6448, -52.6854, -48.0042, -41.3739, -45.0748, -46.1313,\n",
            "        -44.2312, -43.5201, -42.0362, -47.5573, -49.9541, -42.8470, -43.0699,\n",
            "        -48.6505, -92.1781], device='cuda:0')\n",
            "log-likelihood  estimate : tensor(-46.1778, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G87OirLlLNDm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaEut84nLM3t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS0RJ_oV9qIc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhJyYzMx9qF1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}