{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2_VAE_Importance_Sampling",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarmanishjha/6135_3/blob/master/Q2_VAE_Importance_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-q85BwZSsj_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Work in progress !!**\n",
        "\n",
        "***Task Completed :***\n",
        "\n",
        "*   Architecture\n",
        "*   Train VAE\n",
        "*   Implement ELBO\n",
        "*   Achieve an ELBO of ≥−96\n",
        "*   Returns:–(logp(x1),...,logp(xM)) estimates of size (M,)\n",
        "\n",
        "***To Do:***\n",
        "* Nothing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xNrPKkzu9R4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOwcsoJb9b_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location, filename = filename, md5=None)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nv_8Y33A9nCU",
        "colab_type": "code",
        "outputId": "4f25241b-98ba-49f5-9e6e-92961e961125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "bs = 128\n",
        "\n",
        "train, valid, test = get_data_loader(\"binarized_mnist\", bs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/78400000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "78405632it [00:09, 7994937.03it/s]                              \n",
            "  0%|          | 16384/15680000 [00:00<01:37, 161335.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:02, 6208347.61it/s]                              \n",
            "  0%|          | 16384/15680000 [00:00<01:38, 159182.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:01, 10690283.65it/s]                             \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xSwlEYJz9qik",
        "colab_type": "code",
        "outputId": "ad56c12f-ce35-400c-c8e4-8cba59544b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKeOXmjJ+qSnjl5oyfqkp45eaMn6pqf8HVmWnn4rDZVwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "48Z9N4cK9qf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input, size=256):\n",
        "        return input.view(input.size(0), size, 1, 1)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  \n",
        "    def __init__(self, image_channels=1, h_dim=256, z_dim=100):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Q(z|X) -- encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 256, kernel_size=5),\n",
        "            nn.ELU(),\n",
        "            Flatten()\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        # P(X|z) -- decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            \n",
        "            UnFlatten(),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(256, 64, kernel_size= 5, padding= 4),\n",
        "            nn.ELU(),\n",
        "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=2),\n",
        "            nn.ELU(),\n",
        "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding = 2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(16, image_channels, kernel_size = 3, padding = 2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "      \n",
        "        \"\"\"std = logvar.mul(0.5).exp_()\n",
        "        esp = torch.randn(*mu.size())\n",
        "        z = mu + std * esp\"\"\"\n",
        "        eps = torch.randn(mu.size()).cuda()\n",
        "        z = eps.mul(logvar.mul(0.5).exp_()).add_(mu)\n",
        "          \n",
        "        logq_xz = torch.distributions.MultivariateNormal(mu,  torch.eye(100).cuda())\n",
        "        q_xz = logq_xz.log_prob(z)\n",
        "        \n",
        "        log_p_z = torch.distributions.MultivariateNormal(torch.zeros(100).cuda(), torch.eye(100).cuda())\n",
        "        p_z = log_p_z.log_prob(z)\n",
        "                \n",
        "        return z, q_xz, p_z\n",
        "\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu, logvar = self.fc1(h), self.fc2(h)\n",
        "        z, q_xz, p_z = self.reparameterize(mu, logvar)\n",
        "        return z, q_xz, p_z, mu, logvar\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        h = self.encoder(x)\n",
        "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
        "        z_decoder = self.fc3(z)\n",
        "        decoder = self.decoder(z_decoder)\n",
        "        \n",
        "        return decoder, mu, logvar\n",
        "      \n",
        "    def imp_sample(self, x, h):\n",
        "        \n",
        "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
        "        \n",
        "        z_decoder = self.fc3(z)\n",
        "        decoder = self.decoder(z_decoder)\n",
        "        \n",
        "        log_p_xz = torch.distributions.Bernoulli(decoder.view(decoder.size(0),784))\n",
        "        p_xz = log_p_xz.log_prob(x.view(x.size(0),784))\n",
        "        \n",
        "        return p_xz, q_xz, p_z\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSSFbJNzIL2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "model = VAE().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss(reduction = \"sum\").cuda()\n",
        "\n",
        "def loss_fn(recon_x, x, mu, logvar):\n",
        "    ## E[log P(X|z)]\n",
        "    \n",
        "    BCE = criterion(recon_x, x)\n",
        "    KLD = - 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp() )\n",
        "    return BCE + KLD, BCE, KLD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vIC-9Bj-9qVk",
        "colab_type": "code",
        "outputId": "fcb5a27b-1e5b-43ca-e0a8-9b5283647fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(train):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_kld/total_images)\n",
        "    print(\"Training Data : \", to_print)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Data :  Epoch[1/20] ELBO: -213.702 ,BCE: 198.928 ,KLD: 14.773\n",
            "Training Data :  Epoch[2/20] ELBO: -141.339 ,BCE: 119.012 ,KLD: 22.326\n",
            "Training Data :  Epoch[3/20] ELBO: -122.331 ,BCE: 99.563 ,KLD: 22.768\n",
            "Training Data :  Epoch[4/20] ELBO: -113.821 ,BCE: 90.525 ,KLD: 23.296\n",
            "Training Data :  Epoch[5/20] ELBO: -109.154 ,BCE: 85.163 ,KLD: 23.991\n",
            "Training Data :  Epoch[6/20] ELBO: -106.210 ,BCE: 81.722 ,KLD: 24.488\n",
            "Training Data :  Epoch[7/20] ELBO: -104.188 ,BCE: 79.395 ,KLD: 24.792\n",
            "Training Data :  Epoch[8/20] ELBO: -102.789 ,BCE: 77.800 ,KLD: 24.989\n",
            "Training Data :  Epoch[9/20] ELBO: -101.674 ,BCE: 76.512 ,KLD: 25.161\n",
            "Training Data :  Epoch[10/20] ELBO: -100.787 ,BCE: 75.492 ,KLD: 25.295\n",
            "Training Data :  Epoch[11/20] ELBO: -99.990 ,BCE: 74.612 ,KLD: 25.377\n",
            "Training Data :  Epoch[12/20] ELBO: -99.346 ,BCE: 73.880 ,KLD: 25.466\n",
            "Training Data :  Epoch[13/20] ELBO: -98.656 ,BCE: 73.144 ,KLD: 25.512\n",
            "Training Data :  Epoch[14/20] ELBO: -98.145 ,BCE: 72.562 ,KLD: 25.584\n",
            "Training Data :  Epoch[15/20] ELBO: -97.703 ,BCE: 72.058 ,KLD: 25.645\n",
            "Training Data :  Epoch[16/20] ELBO: -97.261 ,BCE: 71.537 ,KLD: 25.724\n",
            "Training Data :  Epoch[17/20] ELBO: -96.852 ,BCE: 71.099 ,KLD: 25.753\n",
            "Training Data :  Epoch[18/20] ELBO: -96.425 ,BCE: 70.629 ,KLD: 25.796\n",
            "Training Data :  Epoch[19/20] ELBO: -96.196 ,BCE: 70.337 ,KLD: 25.860\n",
            "Training Data :  Epoch[20/20] ELBO: -95.774 ,BCE: 69.925 ,KLD: 25.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8PQZAB6X9qK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Q(z|X) -- encoder\n",
        "# P(X|z) -- decoder\n",
        "#p(z) -- latent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5g6mTp92ffR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "cf9d133e-02c5-4882-994e-c70516c06fd3"
      },
      "cell_type": "code",
      "source": [
        "#ELBO Validation Data:\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(valid):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "\n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_kld/total_images)\n",
        "    print(\"Validation Data : \", to_print)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Data :  Epoch[1/1] ELBO: -96.005 ,BCE: 69.294 ,KLD: 26.711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8eu7RC32jDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "7b866bc5-7015-47ba-87cf-db1184d0e544"
      },
      "cell_type": "code",
      "source": [
        "#ELBO Test Data:\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "    total_loss = 0\n",
        "    total_images = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0 \n",
        "    for idx, (images) in enumerate(test):\n",
        "        images = images.to(device)\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
        "\n",
        "        total_loss += loss.data\n",
        "        total_bce += bce.data\n",
        "        total_kld += kld.data\n",
        "        total_images += images.size(0)\n",
        "        \n",
        "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
        "                            epochs, -total_loss/total_images, total_bce/total_images, total_images/total_images)\n",
        "    print(\"Test Data : \", to_print)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Data :  Epoch[1/1] ELBO: -95.211 ,BCE: 68.667 ,KLD: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n6Os3QJwSSYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Importance Sampling Function:\n",
        "\n",
        "def importance_sampling(model, data):\n",
        "    #Input as our trained model and data\n",
        "  \n",
        "    ip_loss = []\n",
        "    count = 0\n",
        "    #Setting the model parameters to no_grad\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    for idx, (images) in enumerate(valid):\n",
        "        images = images.to(device)\n",
        "        count += 1\n",
        "        #Calling model to get the output from encoder\n",
        "        h = model.encoder(images.view(images.size(0),1,28,28))\n",
        "        h = h.view(images.size(0),256)\n",
        "\n",
        "        ip_sample = []\n",
        "\n",
        "        for k in range(200):\n",
        "            #Calling model to get output of our densities :\n",
        "            p_xz, q_xz, p_z = model.imp_sample(images, h)\n",
        "            #Summing over 784 dimention and the dimention we will have (1XBatch_Size)\n",
        "            p_xz = torch.sum(p_xz,dim=1)\n",
        "            #Importance Sampling calculation with LogSumExp trick:\n",
        "            out = p_xz - q_xz + p_z\n",
        "            log_weight = out - torch.max(out, 0)[0]\n",
        "            weight = torch.exp(log_weight)\n",
        "            weight = weight / torch.sum(weight, 0)\n",
        "            loss = torch.mean(torch.sum(weight * (p_z + p_xz - q_xz), 0))\n",
        "            ip_sample.append(loss)\n",
        "\n",
        "        ip_loss.append(torch.sum(torch.stack(ip_sample))/bs)\n",
        "\n",
        "    print(\"Importance Sampling over mini batch -\", count,' : ' , torch.stack(ip_loss))\n",
        "\n",
        "    log_likelihood_estimate = torch.mean(torch.stack(ip_loss))\n",
        "    print('log-likelihood  estimate :', log_likelihood_estimate)\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nyoSgq28TiRD",
        "colab_type": "code",
        "outputId": "d286eb71-bb9c-4606-fe7d-29ffb20c4e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "#Importance Sampling on Validation Data:\n",
        "importance_sampling(model, valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Importance Sampling over mini batch - 79  :  tensor([-51.7519, -40.9928, -41.9688, -46.6459, -42.4130, -38.6475, -49.3180,\n",
            "        -51.9250, -49.2326, -47.2400, -49.1583, -43.8565, -43.8202, -44.8767,\n",
            "        -43.7532, -42.8402, -46.4243, -49.3233, -43.2348, -49.6836, -44.7124,\n",
            "        -46.7302, -48.0831, -49.9344, -47.7950, -45.1786, -47.8287, -46.6879,\n",
            "        -46.1231, -44.2850, -44.0064, -49.5948, -46.6224, -43.1792, -42.5128,\n",
            "        -41.6820, -47.1679, -43.5925, -44.8092, -48.2863, -50.3733, -42.4824,\n",
            "        -46.2240, -43.1253, -43.3580, -42.5984, -42.1227, -46.7130, -44.9543,\n",
            "        -49.1215, -47.8726, -45.6109, -35.2775, -44.2597, -49.3639, -47.0719,\n",
            "        -45.0195, -43.1482, -45.8838, -48.7599, -44.1559, -48.9082, -43.0310,\n",
            "        -44.1631, -47.1068, -51.6412, -47.2906, -41.0335, -46.9298, -45.2434,\n",
            "        -45.7410, -44.8673, -42.7586, -47.2907, -50.1011, -45.3172, -41.2663,\n",
            "        -49.9883, -93.6936], device='cuda:0')\n",
            "log-likelihood  estimate : tensor(-46.3264, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hLBw7wyMTu-P",
        "colab_type": "code",
        "outputId": "45c30b5d-afd5-4c94-94cf-acd809e77f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "cell_type": "code",
      "source": [
        "#Importance Sampling on Test Data:\n",
        "importance_sampling(model, test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Importance Sampling over mini batch - 79  :  tensor([-52.7230, -38.5022, -41.5454, -44.8406, -42.1316, -39.2519, -48.6957,\n",
            "        -52.1163, -49.4720, -48.8493, -48.6751, -43.5811, -45.4943, -44.7466,\n",
            "        -43.0537, -42.2316, -45.8955, -48.1179, -41.5966, -46.0453, -44.4864,\n",
            "        -46.6894, -48.7502, -49.4452, -45.5944, -42.2726, -45.6959, -47.1088,\n",
            "        -46.0568, -43.9493, -40.0193, -48.3433, -46.4479, -43.6426, -41.9381,\n",
            "        -39.0924, -47.6184, -44.0960, -43.6848, -47.2630, -48.8614, -41.6990,\n",
            "        -46.9828, -42.6285, -40.8621, -42.3729, -40.9367, -43.7882, -44.5581,\n",
            "        -49.4060, -48.0522, -47.0951, -34.7636, -44.6727, -49.9396, -47.3049,\n",
            "        -44.7363, -43.8361, -45.1213, -48.0192, -43.4353, -50.8232, -41.6098,\n",
            "        -42.8519, -46.1503, -51.6169, -47.4296, -40.6439, -46.2924, -45.4969,\n",
            "        -43.3647, -43.7505, -42.3943, -45.9587, -50.8289, -44.2461, -43.2137,\n",
            "        -49.3374, -89.8843], device='cuda:0')\n",
            "log-likelihood  estimate : tensor(-45.7560, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G87OirLlLNDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AaEut84nLM3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mS0RJ_oV9qIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhJyYzMx9qF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}